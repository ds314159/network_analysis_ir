{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploration des données du corpus d'articles scientifiques",
   "id": "6aa0e703917d7589"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Imports des bibliothèques et modules nécessaires\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Ajouter le répertoire parent au chemin de recherche\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import des modules du projet\n",
    "from src.config.config import load_config\n",
    "from src.data_acquisition.data_loader import DataLoader\n",
    "from src.data_acquisition.data_cleaner import DataCleaner\n",
    "from src.data_acquisition.data_explorer import DataExplorer"
   ],
   "id": "initial_id",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Chargement des données",
   "id": "e8a7e43c762a9ec1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T11:52:45.373698Z",
     "start_time": "2025-03-12T11:52:44.811622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargement de la configuration (par defaut, on peut par exemple en définir une par corpus etc dans le fichier ./config/config.py))\n",
    "config = load_config()\n",
    "\n",
    "# Chemin vers le fichier de données\n",
    "data_path = Path(\"../data/raw/data_project.csv\")\n",
    "\n",
    "# Vérifier si le fichier existe\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Le fichier {data_path} n'existe pas.\")\n",
    "\n",
    "# Créer un objet DataLoader\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "# Charger les données\n",
    "df = data_loader.load_from_csv(data_path)\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(f\"Dimensions du DataFrame: {df.shape}\")\n",
    "df.head()"
   ],
   "id": "bcee321efcb58f10",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Prétraitement des données",
   "id": "9def18781a2ea890"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T11:52:49.359830Z",
     "start_time": "2025-03-12T11:52:49.087448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer un objet DataCleaner\n",
    "data_cleaner = DataCleaner(config)\n",
    "\n",
    "# Convertir le DataFrame en liste de dictionnaires\n",
    "documents = df.to_dict('records')\n",
    "\n",
    "# Nettoyage des données\n",
    "cleaned_docs = []\n",
    "for doc in documents:\n",
    "    # Assurer que tous les champs nécessaires existent\n",
    "    if 'abstract' not in doc or doc['abstract'] is None:\n",
    "        doc['abstract'] = \"\"\n",
    "    \n",
    "    # Nettoyer le texte de l'abstract\n",
    "    if doc['abstract']:\n",
    "        doc['abstract'] = data_cleaner.clean_text(doc['abstract'])\n",
    "    \n",
    "    # Convertir les références en liste si ce n'est pas déjà le cas\n",
    "    if 'references' in doc and isinstance(doc['references'], str):\n",
    "        # Si les références sont une chaîne sous forme de liste Python\n",
    "        if doc['references'].startswith('[') and doc['references'].endswith(']'):\n",
    "            try:\n",
    "                doc['references'] = eval(doc['references'])\n",
    "            except:\n",
    "                doc['references'] = []\n",
    "        else:\n",
    "            # Sinon, diviser sur les virgules\n",
    "            doc['references'] = [ref.strip() for ref in doc['references'].split(',') if ref.strip()]\n",
    "    \n",
    "    # Assurer que class est un entier\n",
    "    if 'class' in doc and doc['class']:\n",
    "        try:\n",
    "            doc['class'] = int(doc['class'])\n",
    "        except:\n",
    "            doc['class'] = None\n",
    "    \n",
    "    # Convertir les auteurs en liste si ce n'est pas déjà le cas\n",
    "    if 'authors' in doc and isinstance(doc['authors'], str):\n",
    "        if doc['authors'].startswith('[') and doc['authors'].endswith(']'):\n",
    "            try:\n",
    "                doc['authors'] = eval(doc['authors'])\n",
    "            except:\n",
    "                doc['authors'] = []\n",
    "        else:\n",
    "            doc['authors'] = [author.strip() for author in doc['authors'].split(',') if author.strip()]\n",
    "    \n",
    "    cleaned_docs.append(doc)\n",
    "\n",
    "print(f\"Nombre de documents après nettoyage: {len(cleaned_docs)}\")\n",
    "cleaned_docs[0]  # Afficher le premier document nettoyé"
   ],
   "id": "d753c15e12e73eeb",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Analyse statistique de base",
   "id": "afb262701359df32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:57:09.974190Z",
     "start_time": "2025-03-12T09:57:09.967189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Créer un objet DataExplorer\n",
    "data_explorer = DataExplorer(cleaned_docs)\n",
    "\n",
    "# Obtenir les statistiques de base\n",
    "stats = data_explorer.get_basic_stats()\n",
    "\n",
    "# Afficher les statistiques\n",
    "print(\"Statistiques du corpus:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"- {key}:\")\n",
    "        for subkey, subvalue in value.items():\n",
    "            print(f\"  - {subkey}: {subvalue}\")\n",
    "    else:\n",
    "        print(f\"- {key}: {value}\")"
   ],
   "id": "513f20bf2e84cb9",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Visualisation de la distribution des classes",
   "id": "6ad613c5c7d56d5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:57:58.116803Z",
     "start_time": "2025-03-12T09:57:57.834979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualiser la distribution des classes\n",
    "data_explorer.visualize_class_distribution()\n",
    "\n",
    "# Afficher les noms des classes avec leur description\n",
    "class_descriptions = {\n",
    "    1: \"Intelligence Artificielle\",\n",
    "    2: \"Science des Données\",\n",
    "    3: \"Interface\",\n",
    "    4: \"Vision par Ordinateur\",\n",
    "    5: \"Réseau\",\n",
    "    6: \"Informatique Théorique\",\n",
    "    7: \"Applications Spécifiques\",\n",
    "    8: \"Autres\"\n",
    "}\n",
    "\n",
    "print(\"\\nClasses et leurs descriptions:\")\n",
    "for cls, desc in class_descriptions.items():\n",
    "    print(f\"- Classe {cls}: {desc}\")"
   ],
   "id": "9417d4699590087a",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Analyse temporelle",
   "id": "a5f9d0eb82696872"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:58:59.427627Z",
     "start_time": "2025-03-12T09:58:59.256629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obtenir la distribution temporelle\n",
    "temporal_dist = data_explorer._get_temporal_distribution()\n",
    "\n",
    "# Convertir en DataFrame pour faciliter la visualisation\n",
    "temp_df = pd.DataFrame(list(temporal_dist.items()), columns=['Year', 'Count'])\n",
    "temp_df = temp_df.sort_values('Year')\n",
    "\n",
    "# Visualiser la distribution temporelle\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(temp_df['Year'], temp_df['Count'])\n",
    "plt.title('Distribution des documents par année')\n",
    "plt.xlabel('Année')\n",
    "plt.ylabel('Nombre de documents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques sur la distribution temporelle\n",
    "if len(temp_df) > 0:\n",
    "    print(f\"Année la plus ancienne: {temp_df['Year'].min()}\")\n",
    "    print(f\"Année la plus récente: {temp_df['Year'].max()}\")\n",
    "    print(f\"Année avec le plus de publications: {temp_df.loc[temp_df['Count'].idxmax(), 'Year']} avec {temp_df['Count'].max()} documents\")"
   ],
   "id": "4fcf4728a46a1385",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Analyse des auteurs",
   "id": "688d91e346dd22a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:59:32.178591Z",
     "start_time": "2025-03-12T09:59:31.986073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compter le nombre de publications par auteur\n",
    "author_counts = Counter()\n",
    "for doc in cleaned_docs:\n",
    "    if 'authors' in doc and doc['authors']:\n",
    "        for author in doc['authors']:\n",
    "            author_counts[author] += 1\n",
    "\n",
    "# Obtenir les auteurs les plus prolifiques\n",
    "top_authors = author_counts.most_common(10)\n",
    "\n",
    "# Visualiser les auteurs les plus prolifiques\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([author for author, count in top_authors], [count for author, count in top_authors])\n",
    "plt.title('Top 10 des auteurs les plus prolifiques')\n",
    "plt.xlabel('Auteur')\n",
    "plt.ylabel('Nombre de publications')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques sur les auteurs\n",
    "print(f\"Nombre total d'auteurs: {len(author_counts)}\")\n",
    "print(f\"Nombre moyen d'auteurs par document: {sum(len(doc.get('authors', [])) for doc in cleaned_docs) / len(cleaned_docs):.2f}\")\n",
    "print(\"\\nTop 10 des auteurs les plus prolifiques:\")\n",
    "for author, count in top_authors:\n",
    "    print(f\"- {author}: {count} publications\")"
   ],
   "id": "8832a5271c0d5cea",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Analyse des mots-clés",
   "id": "c734ad7fc9e102fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:00:27.115018Z",
     "start_time": "2025-03-12T10:00:25.841720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concaténer tous les abstracts\n",
    "all_abstracts = \" \".join([doc.get('abstract', '') for doc in cleaned_docs if doc.get('abstract')])\n",
    "\n",
    "# Nettoyer le texte des abstracts\n",
    "cleaned_abstracts = data_cleaner.clean_text(all_abstracts)\n",
    "\n",
    "# Tokeniser\n",
    "tokens = cleaned_abstracts.split()\n",
    "\n",
    "# Supprimer les mots vides\n",
    "tokens_without_stopwords = data_cleaner.remove_stop_words(tokens)\n",
    "\n",
    "# Compter les occurrences des termes\n",
    "term_counts = Counter(tokens_without_stopwords)\n",
    "\n",
    "# Obtenir les termes les plus fréquents\n",
    "top_terms = term_counts.most_common(20)\n",
    "\n",
    "# Visualiser les termes les plus fréquents\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([term for term, count in top_terms], [count for term, count in top_terms])\n",
    "plt.title('Top 20 des termes les plus fréquents dans les abstracts')\n",
    "plt.xlabel('Terme')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Créer un nuage de mots\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate_from_frequencies(term_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Nuage de mots des termes les plus fréquents')\n",
    "plt.show()"
   ],
   "id": "fa067557e418efd5",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Analyse des références",
   "id": "e9021e3069610ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:01:05.613633Z",
     "start_time": "2025-03-12T10:01:05.408457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculer le nombre de références par document\n",
    "ref_counts = [len(doc.get('references', [])) for doc in cleaned_docs]\n",
    "\n",
    "# Visualiser la distribution du nombre de références\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ref_counts, bins=20)\n",
    "plt.title('Distribution du nombre de références par document')\n",
    "plt.xlabel('Nombre de références')\n",
    "plt.ylabel('Nombre de documents')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques sur les références\n",
    "print(f\"Nombre moyen de références par document: {np.mean(ref_counts):.2f}\")\n",
    "print(f\"Nombre médian de références par document: {np.median(ref_counts):.2f}\")\n",
    "print(f\"Nombre maximum de références pour un document: {np.max(ref_counts)}\")\n",
    "print(f\"Nombre de documents sans références: {sum(1 for count in ref_counts if count == 0)}\")"
   ],
   "id": "ea47c6b93eecd190",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Analyse des venues (lieux de publication)",
   "id": "fd370dfd9ed0c0e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:01:55.508004Z",
     "start_time": "2025-03-12T10:01:55.339173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compter les occurrences des venues\n",
    "venue_counts = Counter([doc.get('venue', '') for doc in cleaned_docs if doc.get('venue')])\n",
    "\n",
    "# Obtenir les venues les plus fréquentes\n",
    "top_venues = venue_counts.most_common(10)\n",
    "\n",
    "# Visualiser les venues les plus fréquentes\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar([venue for venue, count in top_venues], [count for venue, count in top_venues])\n",
    "plt.title('Top 10 des lieux de publication les plus fréquents')\n",
    "plt.xlabel('Lieu de publication')\n",
    "plt.ylabel('Nombre de documents')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques sur les venues\n",
    "print(f\"Nombre total de lieux de publication distincts: {len(venue_counts)}\")\n",
    "print(\"\\nTop 10 des lieux de publication:\")\n",
    "for venue, count in top_venues:\n",
    "    print(f\"- {venue}: {count} documents\")"
   ],
   "id": "3482c36df65b5f84",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Cette analyse exploratoire nous a permis de mieux comprendre la structure du corpus :\n",
    "\n",
    "- les principales classes et leur distribution\n",
    "- l'évolution temporelle des publications\n",
    "- les auteurs les plus prolifiques\n",
    "- les termes les plus fréquents\n",
    "- la structure des références\n",
    "- les lieux de publication les plus courants\n",
    "\n"
   ],
   "id": "91b97daa8c72e719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "41b0c8c781c2e96b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "590fdad4d0e7212f",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d2bd62c80d523e32",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "5f1579c2c2d07ef0",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
